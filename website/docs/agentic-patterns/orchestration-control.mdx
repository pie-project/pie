---
title: Orchestration & Control
description: Patterns for coordinating agents, managing execution flow, and scaling reasoning
sidebar_position: 3
---

# Orchestration & Control

These patterns coordinate multiple agents, manage execution flow, and scale reasoning. They leverage Pie's ability to run many contexts on the same model with shared KV cache and zero API overhead.

---

## Tree-of-Thought

Explore a search tree of intermediate reasoning steps. Branch at each step, evaluate partial solutions, and prune bad paths before committing.

*[Reference →](https://agentic-patterns.com/patterns/tree-of-thought-reasoning/)*

**When to use:**
- Complex puzzles or planning tasks
- Multiple valid approaches exist
- Backtracking may be needed

```
              [Problem]
              /   |   \
          [A]    [B]    [C]       ← branch
          / \    / \      ✗
       [A1] [A2][B1][B2]          ← evaluate + prune
        │    ✗    ✓   ✗
      [A1a]     [best]
```

```rust
// Shared prefix: problem statement
ctx.system("Think step by step. Show your reasoning.");
ctx.user(&problem);
ctx.cue();
ctx.flush().await?;

// Branch: generate N candidate first steps
let mut branches = Vec::new();
for i in 0..num_branches {
    let branch = ctx.fork(&format!("branch-{i}"))?;
    let step = branch.generate(sampler.clone())
        .with_max_tokens(256)
        .collect_text().await?;
    branches.push((branch, step));
}

// Evaluate: score each branch
let mut best = (f32::MIN, 0);
for (i, (branch, step)) in branches.iter().enumerate() {
    let eval = ctx.fork(&format!("eval-{i}"))?;
    eval.user(&format!("Rate this reasoning step 0-1:\n{step}"));
    eval.cue();
    let score_text = eval.generate(sampler.clone())
        .with_max_tokens(32)
        .collect_text().await?;
    let score = parse_score(&score_text);
    if score > best.0 {
        best = (score, i);
    }
}

// Continue from best branch
let winner = &branches[best.1].0;
let continuation = winner.generate(sampler.clone())
    .with_max_tokens(512)
    .collect_text().await?;
```

:::tip[Why Pie]
`fork()` is O(1) copy-on-write — all branches share the problem prefix's KV cache. Pruned branches release their pages instantly. With a standard API, each branch resends the entire prompt.
:::

---

## Language Agent Tree Search (LATS)

Apply Monte Carlo Tree Search to LLM reasoning: select promising nodes (UCB), expand with the LLM, evaluate, and backpropagate values.

*[Reference →](https://agentic-patterns.com/patterns/language-agent-tree-search-lats/)*

**When to use:**
- Multi-step reasoning where greedy approaches get stuck
- Strategic planning with multiple valid approaches
- Tasks where you can score partial solutions

```
 Select ──▶ Expand ──▶ Evaluate ──▶ Backpropagate
   │           │          │              │
   └───────────┴──────────┴──────────────┘
                    (repeat)
```

```rust
struct Node {
    ctx: Context,
    value: f32,
    visits: u32,
    children: Vec<Node>,
}

fn ucb_select(node: &Node) -> usize {
    node.children.iter().enumerate()
        .map(|(i, c)| {
            let exploit = c.value / c.visits as f32;
            let explore = (2.0 * (node.visits as f32).ln() / c.visits as f32).sqrt();
            (i, exploit + explore)
        })
        .max_by(|a, b| a.1.partial_cmp(&b.1).unwrap())
        .unwrap().0
}

// MCTS loop
for _ in 0..iterations {
    // Select: walk tree using UCB
    let leaf = select_leaf(&mut root);

    // Expand: generate candidate actions via LLM
    for i in 0..breadth {
        let child_ctx = leaf.ctx.fork(&format!("expand-{i}"))?;
        child_ctx.cue();
        let _action = child_ctx.generate(sampler.clone())
            .with_max_tokens(128)
            .collect_text().await?;
        leaf.children.push(Node {
            ctx: child_ctx, value: 0.0, visits: 0, children: vec![],
        });
    }

    // Evaluate + Backpropagate
    for child in &mut leaf.children {
        let score = evaluate(&child.ctx).await?;
        backpropagate(child, score);
    }
}
```

:::tip[Why Pie]
Each tree node holds a live `Context` with its KV cache intact. Expansion via `fork()` is O(1) — the child inherits all parent computation. This makes MCTS over LLM reasoning practical rather than prohibitively expensive.
:::

---

## Inference-Time Scaling (Best-of-N)

Generate multiple candidate outputs from the same prompt and select the best one. Allocate more compute for harder problems.

*[Reference →](https://agentic-patterns.com/patterns/inference-time-scaling/)*

**When to use:**
- Problems with verifiable solutions (math, code)
- Quality matters more than latency
- Want to trade compute for accuracy

```
              ┌── Candidate 1 ──┐
              │                 │
 Prompt ──────┼── Candidate 2 ──┼──▶ Score ──▶ Best
              │                 │
              └── Candidate N ──┘
```

```rust
let n = 5;
let mut candidates = Vec::new();

for i in 0..n {
    // All candidates share the prompt's KV cache
    let branch = ctx.fork(&format!("candidate-{i}"))?;
    branch.cue();
    let text = branch.generate(sampler.clone())
        .with_max_tokens(512)
        .collect_text().await?;
    candidates.push(text);
}

// Score and select best
let best = candidates.iter()
    .map(|c| (score(c), c))
    .max_by(|a, b| a.0.partial_cmp(&b.0).unwrap())
    .unwrap().1;
```

:::tip[Why Pie]
All N candidates share the prompt prefix via copy-on-write `fork()`. Memory and compute scale with the *generated* tokens, not the prompt length. A 2000-token prompt with 5 candidates costs ~the same as 1 candidate plus the divergent tokens.
:::

---

## Self-Rewriting Meta-Prompt

After each episode, the agent reflects on what worked and proposes edits to its own system prompt, which are validated and applied for the next episode.

*[Reference →](https://agentic-patterns.com/patterns/self-rewriting-meta-prompt-loop/)*

**When to use:**
- Agent encounters recurring failures
- Prompt needs frequent minor tweaks
- Continuous learning without human intervention

```
 Episode ──▶ Reflect ──▶ Propose Δ ──▶ Guardrail ──┬──▶ Apply to Prompt
    ▲                                               │
    └───────────────────────────────────────────────┘
```

```rust
// Run episode
let episode_ctx = ctx.fork("episode")?;
episode_ctx.user(&task);
episode_ctx.cue();
let result = episode_ctx.generate(sampler.clone())
    .with_max_tokens(1024)
    .collect_text().await?;

// Reflect and propose prompt edits
let reflect = ctx.fork("reflect")?;
reflect.user(&format!(
    "You just completed a task. Result:\n{result}\n\n\
     Propose improvements to the system prompt to handle \
     similar tasks better. Output only the delta."
));
reflect.cue();
let delta = reflect.generate(sampler.clone())
    .with_max_tokens(256)
    .collect_text().await?;

// Validate and apply (with guardrails)
if passes_guardrails(&delta) {
    system_prompt.push_str(&format!("\n{delta}"));
}
```

---

## Posterior Sampling Planner

Maintain a belief distribution over possible task models, sample a model, compute the optimal plan for that model, execute, observe results, and update beliefs.

*[Reference →](https://agentic-patterns.com/patterns/explicit-posterior-sampling-planner/)*

**When to use:**
- Exploration-heavy tasks where the right approach is unknown
- Multi-step decisions with uncertainty
- Want principled exploration vs. exploitation

```
 Beliefs ──▶ Sample Strategy ──▶ Execute ──▶ Observe Reward
    ▲                                            │
    └────────── Update Beliefs ◀─────────────────┘
```

```rust
let mut beliefs: Vec<(String, f32)> = strategies.iter()
    .map(|s| (s.clone(), 1.0))  // Uniform prior
    .collect();

for round in 0..max_rounds {
    // Sample strategy proportional to belief
    let strategy = sample_weighted(&beliefs);

    // Execute with sampled strategy
    let trial = ctx.fork(&format!("trial-{round}"))?;
    trial.system(&format!("Use this strategy: {strategy}"));
    trial.user(&task);
    trial.cue();
    let result = trial.generate(sampler.clone())
        .with_max_tokens(512)
        .collect_text().await?;

    // Observe and update beliefs
    let reward = evaluate_result(&result);
    update_beliefs(&mut beliefs, &strategy, reward);
}
```

:::tip[Why Pie]
Each trial is a forked context that shares the task prefix. Failed strategies are cheaply discarded. The belief update happens in inferlet code — no external orchestration needed.
:::

---

## ReAct (Reasoning + Acting)

Interleave reasoning and tool calls in a loop: think → act → observe → think → …

*[Reference →](https://agentic-patterns.com/patterns/autonomous-workflow-agent-architecture/)*

**When to use:**
- Tasks requiring external information (search, databases, APIs)
- Multi-step problem solving
- Autonomous agent workflows

```
 Think ──▶ Tool Call ──▶ Observe ──▶ Think ──▶ … ──▶ Answer
```

```rust
use inferlet::{Event, InstructExt};

ctx.system("You are a helpful assistant with access to tools.");
ctx.equip_tools(&tool_schemas)?;
ctx.user(&question);
ctx.cue();

for _ in 0..max_iterations {
    let mut events = ctx.generate(sampler.clone())
        .with_max_tokens(512)
        .decode()
        .with_reasoning()
        .with_tool_use();

    let mut tool_call = None;

    while let Some(event) = events.next().await? {
        match event {
            Event::ToolCall(name, args) => {
                tool_call = Some((name, args));
                break;
            }
            Event::Text(s) => send_text(&s).await,
            Event::Done(_) => return Ok(()),
            _ => {}
        }
    }

    if let Some((name, args)) = tool_call {
        let result = dispatch_tool(&name, &args)?;
        ctx.answer_tool(&name, &result);
        ctx.cue();
    } else {
        break;
    }
}
```

:::tip[Why Pie]
The KV cache persists across the entire loop. Each tool turn appends to existing state — the model never re-processes the conversation history. This makes 10-turn agent loops nearly as fast as the *marginal* token cost.
:::

---

## Plan-Then-Execute

Split into two phases: the model produces a frozen plan (structured output), then a controller executes it step by step. Tool outputs cannot alter the plan.

*[Reference →](https://agentic-patterns.com/patterns/plan-then-execute-pattern/)*

**When to use:**
- Security-sensitive tasks where tool output shouldn't redirect the agent
- Tasks where the action set is known but parameters vary
- Email/calendar bots, SQL assistants

```
 PLAN PHASE              EXECUTE PHASE
 Prompt ──▶ LLM ──▶ Plan ──▶ Controller ──▶ Results
             │                    │
        (structured)         (no LLM calls)
```

```rust
use inferlet::InstructExt;

// Phase 1: Generate a structured plan
ctx.system("Output a JSON array of tool calls to execute.");
ctx.user(&task);
ctx.cue();

let plan_json = ctx.generate(sampler.clone())
    .with_constraint(json_schema_matcher)
    .with_max_tokens(512)
    .collect_text().await?;

let plan: Vec<ToolCall> = serde_json::from_str(&plan_json)?;

// Phase 2: Execute the frozen plan (no LLM involved)
let mut results = Vec::new();
for call in &plan {
    let result = dispatch_tool(&call.name, &call.args)?;
    results.push(result);
}

// Summarize results
ctx.user(&format!("Results: {}", serde_json::to_string(&results)?));
ctx.cue();
let summary = ctx.generate(sampler)
    .with_max_tokens(256)
    .collect_text().await?;
```

:::tip[Why Pie]
Structured generation (grammar constraints) ensures the plan is valid JSON. The plan phase and summary phase share KV cache. No tool output touches the model during execution, preventing prompt injection.
:::

---

## Action-Selector

Use the LLM purely as a classifier: map user input to an allowlisted action. Tool output is returned directly to the user, *never* fed back to the model.

*[Reference →](https://agentic-patterns.com/patterns/action-selector-pattern/)*

**When to use:**
- High-security environments (banking, medical)
- Customer service bots with limited actions
- Kiosk-style interfaces

```
 User ──▶ LLM ──▶ Action ID ──▶ Execute ──▶ User
                     │
                Allowlist check
                (result NOT fed back to LLM)
```

```rust
let actions = vec!["check_balance", "transfer", "history", "help"];

// Constrain output to exactly one of the allowed actions
let matcher = create_enum_matcher(&model, &actions);

ctx.user(&user_input);
ctx.cue();

let action = ctx.generate(sampler)
    .with_constraint(matcher)
    .with_max_tokens(16)
    .collect_text().await?;

// Execute directly — no LLM feedback loop
let result = execute_action(&action, &user_params)?;
send_to_user(&result).await;
```

:::tip[Why Pie]
Constrained decoding guarantees the output is a valid action — no parsing or retry needed. The model acts as a pure decoder with zero risk of prompt injection since tool results never re-enter the context.
:::

---

## Stop Hook Auto-Continue

Check success criteria after each generation turn. If criteria aren't met (tests fail, format invalid), automatically continue the agent without human intervention.

*[Reference →](https://agentic-patterns.com/patterns/stop-hook-auto-continue-pattern/)*

**When to use:**
- Test-driven development workflows
- Autonomous task completion
- Containerized/sandboxed environments

```
 Agent ──▶ Generate ──▶ Stop Hook ──┬── Pass ──▶ Done
   ▲                                │
   │                            Fail (tests/format)
   │                                │
   └──── Feedback ◀─────────────────┘
```

```rust
let mut succeeded = false;

for turn in 0..max_turns {
    ctx.cue();
    let output = ctx.generate(sampler.clone())
        .with_max_tokens(1024)
        .decode()
        .with_tool_use();

    // Process generation (handle tool calls, etc.)
    process_events(&mut ctx, output).await?;

    // Stop hook: check success criteria
    let check = run_success_check().await?;
    if check.passed {
        succeeded = true;
        break;
    }

    // Auto-continue with feedback
    ctx.user(&format!("Not done yet. Issues:\n{}", check.issues));
}
```

---

## Parallel Tool Calls

Detect when the model requests multiple independent tool calls in a single generation turn and execute them concurrently.

*[Reference →](https://agentic-patterns.com/patterns/parallel-tool-execution/)*

**When to use:**
- Information gathering across multiple sources
- Independent API calls (weather + calendar + email)
- Want to minimize latency

```
                  ┌── Tool A ──┐
 LLM Turn ────────┼── Tool B ──┼──▶ All Results ──▶ Continue
                  └── Tool C ──┘
                   (concurrent)
```

```rust
let mut events = ctx.generate(sampler.clone())
    .with_max_tokens(512)
    .decode()
    .with_tool_use();

// Collect all tool calls from this turn
let mut tool_calls = Vec::new();
while let Some(event) = events.next().await? {
    match event {
        Event::ToolCall(name, args) => {
            tool_calls.push((name, args));
        }
        Event::Done(_) => break,
        _ => {}
    }
}

// Execute all tool calls concurrently
for (name, args) in &tool_calls {
    let result = dispatch_tool(name, args)?;
    ctx.answer_tool(name, &result);
}

// Continue generation with all results
ctx.cue();
```

---

## Tool Compartmentalization

Split a monolithic tool into reader/processor/writer micro-tools with separate permissions. Different agent contexts get different tool subsets.

*[Reference →](https://agentic-patterns.com/patterns/tool-capability-compartmentalization/)*

**When to use:**
- Tools handle private data
- Multiple capability types combined
- Security is high priority

```
 ┌── Reader ctx ──┐     ┌── Writer ctx ──┐
 │ read, search   │     │ send, create   │
 │ (data access)  │────▶│ (no data)      │
 │                │     │ acts on summary│
 └────────────────┘     └────────────────┘
```

```rust
// Reader context: can access data, no write tools
let reader = Context::create(&model, "reader", None)?;
reader.equip_tools(&[read_email_tool, search_tool])?;

// Writer context: can send, no data access
let writer = Context::create(&model, "writer", None)?;
writer.equip_tools(&[send_email_tool, create_ticket_tool])?;

// Reader extracts info (sandboxed)
reader.user("Extract the sender and subject from this email.");
reader.cue();
let info = reader.generate(sampler.clone())
    .with_max_tokens(128)
    .collect_text().await?;

// Writer acts on sanitized info (no access to raw data)
writer.user(&format!("Create a ticket for: {info}"));
writer.cue();
```

:::tip[Why Pie]
Each context has its own tool set and KV cache. The writer never sees raw email data — only the reader's sanitized output. This is enforced at the inferlet level, not by prompting.
:::

---

## Agent-Driven Research

Iterative search loop: formulate a query, execute search, analyze results, refine strategy, and repeat until the information need is satisfied.

*[Reference →](https://agentic-patterns.com/patterns/agent-driven-research/)*

**When to use:**
- Complex research questions
- Multi-source information gathering
- Adaptive search strategies

```
 Question ──▶ Formulate Query ──▶ Search ──▶ Analyze ──┐
                  ▲                                      │
                  │              [SUFFICIENT?] ──▶ Synthesize
                  │                   │ No
                  └───────────────────┘
```

```rust
let mut findings = String::new();

for round in 0..max_rounds {
    // Formulate search query based on current knowledge
    ctx.user(&format!(
        "Current findings:\n{findings}\n\n\
         What should we search for next to answer: {question}"
    ));
    ctx.cue();

    let query = ctx.generate(sampler.clone())
        .with_max_tokens(64)
        .collect_text().await?;

    // Execute search via tools
    let results = search(&query).await?;

    // Analyze and accumulate
    ctx.user(&format!("Search results:\n{results}\n\nExtract key findings."));
    ctx.cue();
    let analysis = ctx.generate(sampler.clone())
        .with_max_tokens(256)
        .collect_text().await?;
    findings.push_str(&format!("\n{analysis}"));

    // Check if satisfied
    if analysis.contains("[SUFFICIENT]") { break; }
}

// Final synthesis
ctx.user(&format!("Synthesize all findings into a final answer:\n{findings}"));
ctx.cue();
let answer = ctx.generate(sampler)
    .with_max_tokens(512)
    .collect_text().await?;
```

:::tip[Why Pie]
Each round builds on the accumulated KV cache. The model's "memory" of previous search results is native — no summarization or truncation needed until you hit cache limits, at which point you can use KV cache eviction strategies.
:::

---

## Sub-Agent Spawning

Split a large task across parallel sub-agents, each with a fresh context. The main agent coordinates and merges results.

*[Reference →](https://agentic-patterns.com/patterns/sub-agent-spawning/)*

**When to use:**
- Multi-file processing (10+ items)
- Tasks that are independently parallelizable
- Context window would overflow with sequential processing

```
 ┌── Sub-1 ──▶ [result] ──┐
 │                         │
 Main ──▶ Split ──┼── Sub-2 ──▶ [result] ──┼──▶ Merge ──▶ Done
 │                         │
 └── Sub-3 ──▶ [result] ──┘
```

```rust
let items = vec!["doc1.md", "doc2.md", "doc3.md"];
let mut results = Vec::new();

for (i, item) in items.iter().enumerate() {
    // Each sub-agent gets a fresh context
    let sub = Context::create(&model, &format!("sub-{i}"), None)?;
    sub.system("You are a document summarizer.");
    sub.user(&format!("Summarize this document:\n{}", load_file(item).await?));
    sub.cue();

    let summary = sub.generate(sampler.clone())
        .with_max_tokens(256)
        .collect_text().await?;
    results.push(summary);
}

// Main agent merges results
ctx.user(&format!(
    "Combine these summaries into a single report:\n\n{}",
    results.iter().enumerate()
        .map(|(i, r)| format!("## {}\n{r}", items[i]))
        .collect::<Vec<_>>().join("\n\n")
));
ctx.cue();
let report = ctx.generate(sampler)
    .with_max_tokens(512)
    .collect_text().await?;
```

:::tip[Why Pie]
All sub-agents share the same model on the same GPU. There's no network overhead or API rate limits — only KV cache memory. Each sub-agent has isolated state, preventing cross-contamination.
:::

---

## Multi-Agent Debate

Spawn opposing agents with different perspectives. They challenge each other's reasoning, surfacing blind spots and reducing bias.

*[Reference →](https://agentic-patterns.com/patterns/opponent-processor-multi-agent-debate/)*

**When to use:**
- Decisions requiring balanced perspectives
- High-stakes choices needing scrutiny
- Tasks prone to confirmation bias

```
 Task ──┬──▶ Advocate ──▶ Propose ──┐
        │                           ├──▶ Synthesize
        └──▶ Critic   ──▶ Challenge ┘
```

```rust
let advocate = Context::create(&model, "advocate", None)?;
advocate.system("You are a strong advocate for the proposed solution. \
    Argue persuasively for why it's the best approach.");

let critic = Context::create(&model, "critic", None)?;
critic.system("You are a rigorous critic. Find flaws, risks, and \
    unconsidered alternatives in the proposed solution.");

// Round 1: Advocate proposes
advocate.user(&format!("Propose a solution for: {task}"));
advocate.cue();
let proposal = advocate.generate(sampler.clone())
    .with_max_tokens(512)
    .collect_text().await?;

// Round 2: Critic challenges
critic.user(&format!("Challenge this proposal:\n{proposal}"));
critic.cue();
let challenge = critic.generate(sampler.clone())
    .with_max_tokens(512)
    .collect_text().await?;

// Round 3: Advocate responds to criticism
advocate.user(&format!("Address these concerns:\n{challenge}"));
advocate.cue();
let defense = advocate.generate(sampler.clone())
    .with_max_tokens(512)
    .collect_text().await?;

// Synthesize
ctx.user(&format!(
    "Given this debate, provide a balanced final decision:\n\n\
     Proposal: {proposal}\n\nCritique: {challenge}\n\nDefense: {defense}"
));
ctx.cue();
let decision = ctx.generate(sampler)
    .with_max_tokens(512)
    .collect_text().await?;
```

:::tip[Why Pie]
Each agent has its own context and system prompt — they can't see each other's internal reasoning, only the exchanged messages. The synthesizer context is separate too, ensuring unbiased aggregation. All three run on the same model with no API overhead.
:::

---

## Oracle & Worker

Use a fast, cheap model for routine tasks. Escalate to a powerful, expensive model only when the worker gets stuck.

*[Reference →](https://agentic-patterns.com/patterns/oracle-and-worker-multi-model/)*

**When to use:**
- Mix of routine and complex tasks
- Cost optimization is important
- Tasks where the worker can detect its own uncertainty

```
 Request ──▶ Worker ──┬──▶ Done
                      │
                   [Stuck?]
                      │
                      └──▶ Oracle ──▶ Strategy ──▶ Worker ──▶ Done
```

```rust
// Worker: fast model for routine work
let worker_model = Model::load_by_name("worker-model")?;
let worker = Context::create(&worker_model, "worker", None)?;
worker.system("Solve the task. If you are uncertain, respond with [ESCALATE].");
worker.user(&task);
worker.cue();

let result = worker.generate(sampler_fast.clone())
    .with_max_tokens(512)
    .collect_text().await?;

if result.contains("[ESCALATE]") {
    // Oracle: powerful model for hard problems
    let oracle_model = Model::load_by_name("oracle-model")?;
    let oracle = Context::create(&oracle_model, "oracle", None)?;
    oracle.system("Provide a detailed strategy for solving this problem.");
    oracle.user(&format!(
        "The worker couldn't solve this. Provide guidance:\n\n{task}"
    ));
    oracle.cue();

    let strategy = oracle.generate(sampler_strong.clone())
        .with_max_tokens(512)
        .collect_text().await?;

    // Worker applies oracle's strategy
    worker.user(&format!("Follow this strategy:\n{strategy}"));
    worker.cue();
    let final_result = worker.generate(sampler_fast)
        .with_max_tokens(512)
        .collect_text().await?;
}
```

:::tip[Why Pie]
Both models are loaded in the same inferlet. Routing is code — no external orchestrator needed. The worker's KV cache persists through escalation, so it retains full context when applying the oracle's strategy.
:::

---

## Dual LLM

Separate the agent into a Privileged LLM (has tools, cannot see raw data) and a Quarantined LLM (sees data, has no tools). They communicate through symbolic variables, never raw content.

*[Reference →](https://agentic-patterns.com/patterns/dual-llm-pattern/)*

**When to use:**
- Processing untrusted documents with tools (e.g., email + calendar)
- High-security environments
- When direct prompt injection is the primary threat

```
 ┌─ Quarantined LLM ─┐     ┌─ Privileged LLM ─┐
 │  Sees raw data     │     │  Has tools         │
 │  No tool access    │────▶│  No raw data       │
 │  Outputs symbols   │     │  Acts on symbols   │
 └────────────────────┘     └────────────────────┘
```

```rust
// Quarantined: reads untrusted data, outputs structured symbols
let quarantined = Context::create(&model, "quarantined", None)?;
quarantined.system(
    "Extract info as JSON. Never output raw content. \
     Use symbolic references like [EMAIL_SENDER], [SUBJECT]."
);
quarantined.user(&raw_email);
quarantined.cue();

let symbols = quarantined.generate(sampler.clone())
    .with_constraint(symbol_schema.clone())
    .with_max_tokens(128)
    .collect_text().await?;

// Privileged: acts on symbols, never sees raw data
let privileged = Context::create(&model, "privileged", None)?;
privileged.system("You are an email assistant with calendar access.");
privileged.equip_tools(&[calendar_tool, notification_tool])?;
privileged.user(&format!(
    "Process this email metadata:\n{symbols}\n\nSchedule if needed."
));
privileged.cue();

let mut events = privileged.generate(sampler)
    .with_max_tokens(256)
    .decode()
    .with_tool_use();

// Handle tool calls safely...
```

:::tip[Why Pie]
The two agents run in separate contexts with independent tool sets. The privileged agent *physically cannot* see the raw email — it's in a different KV cache. This is enforced by the runtime, not by prompting.
:::

---

## LLM Map-Reduce

Process items independently in sandboxed contexts (Map), then aggregate sanitized results (Reduce). Prevents a poisoned item from contaminating global reasoning.

*[Reference →](https://agentic-patterns.com/patterns/llm-map-reduce-pattern/)*

**When to use:**
- Processing untrusted documents
- File triage and classification
- N-to-1 aggregation tasks

```
 MAP                               REDUCE
 [Doc 1] ──▶ Sandbox LLM ──┐
 [Doc 2] ──▶ Sandbox LLM ──┼──▶ Aggregate ──▶ Result
 [Doc 3] ──▶ Sandbox LLM ──┘
       (isolated)           (safe summaries only)
```

```rust
let documents = load_documents().await?;
let mut summaries = Vec::new();

// Map: each document in an isolated context
for (i, doc) in documents.iter().enumerate() {
    let sandbox = Context::create(&model, &format!("map-{i}"), None)?;
    sandbox.system("Classify this document. Output: category, confidence, \
        one-line summary. No other text.");
    sandbox.user(doc);
    sandbox.cue();

    let classification = sandbox.generate(sampler.clone())
        .with_constraint(classification_schema_matcher.clone())
        .with_max_tokens(64)
        .collect_text().await?;

    summaries.push(classification);
    // sandbox is dropped — no cross-contamination
}

// Reduce: aggregate (no raw documents in context)
ctx.system("Summarize the following document classifications.");
ctx.user(&summaries.join("\n"));
ctx.cue();
let report = ctx.generate(sampler)
    .with_max_tokens(256)
    .collect_text().await?;
```

:::tip[Why Pie]
Each sandbox is a separate context with constrained output — a poisoned document cannot inject instructions into the reducer. The reducer sees only structured classifications, never raw documents. All map tasks share the model with zero API overhead.
:::

---

## Iterative Brainstorming

Spawn multiple agents with different perspectives to brainstorm in parallel, then synthesize the best ideas.

*[Reference →](https://agentic-patterns.com/patterns/iterative-multi-agent-brainstorming/)*

**When to use:**
- Creative ideation tasks
- Complex design decisions
- When you want diverse alternatives

```
           ┌── Agent (perf focus)   ──┐
 Task ─────┼── Agent (simplicity)    ──┼──▶ Synthesize ──▶ Best Design
           └── Agent (UX focus)      ──┘
```

```rust
let perspectives = vec![
    "Focus on performance and scalability",
    "Focus on simplicity and maintainability",
    "Focus on user experience and accessibility",
];

let mut ideas = Vec::new();

for (i, perspective) in perspectives.iter().enumerate() {
    let agent = Context::create(&model, &format!("brainstorm-{i}"), None)?;
    agent.system(&format!("You are a software architect. {perspective}"));
    agent.user(&format!("Propose a design for: {task}"));
    agent.cue();

    let idea = agent.generate(sampler.clone())
        .with_max_tokens(512)
        .collect_text().await?;
    ideas.push((perspective, idea));
}

// Synthesize
ctx.user(&format!(
    "Three architects proposed designs. Select the best elements:\n\n{}",
    ideas.iter()
        .map(|(p, i)| format!("**{p}:**\n{i}"))
        .collect::<Vec<_>>().join("\n\n")
));
ctx.cue();
let synthesis = ctx.generate(sampler)
    .with_max_tokens(512)
    .collect_text().await?;
```

---

## Swarm Migration

Orchestrate N parallel agents to process batches of files, like a framework migration or lint fix rollout.

*[Reference →](https://agentic-patterns.com/patterns/swarm-migration-pattern/)*

**When to use:**
- Framework migrations (e.g., updating import styles)
- Lint rule rollouts across many files
- API updates or code modernization

```
 Files ──▶ Batch 1 ──▶ Agent ──▶ Migrate ──▶ Write
           Batch 2 ──▶ Agent ──▶ Migrate ──▶ Write
           Batch N ──▶ Agent ──▶ Migrate ──▶ Write
```

```rust
let files = find_files("**/*.test.js").await?;
let batch_size = 10;

for (batch_idx, batch) in files.chunks(batch_size).enumerate() {
    let agent = Context::create(
        &model, &format!("swarm-{batch_idx}"), None
    )?;
    agent.system(
        "Migrate test files from Jest to Vitest. \
         Change imports and update assertion syntax."
    );

    for file in batch {
        let content = read_file(file).await?;
        agent.user(&format!("Migrate this file ({file}):\n```\n{content}\n```"));
        agent.cue();

        let migrated = agent.generate(sampler.clone())
            .with_max_tokens(1024)
            .collect_text().await?;
        write_file(file, &migrated).await?;
    }
}
```

---

## Initializer-Maintainer

Use two specialized agents: an Initializer creates the project foundation once, a Maintainer handles incremental development across sessions.

*[Reference →](https://agentic-patterns.com/patterns/initializer-maintainer-dual-agent/)*

**When to use:**
- Projects spanning many sessions
- Complex applications with many features
- When context loss between sessions is costly

```
 Session 1:  Initializer ──▶ Create ctx ──▶ Scaffold ──▶ [named ctx saved]
                                                              │
 Session N:  Maintainer  ──▶ lookup(ctx)  ──▶ Add Feature ──▶ [ctx updated]
```

```rust
// Initializer: runs once, creates named context
let init = Context::create(&model, "project-state", None)?;
init.system("You are a project initializer.");
init.user("Set up the project structure for a REST API.");
init.cue();
let scaffold = init.generate(sampler.clone())
    .with_max_tokens(1024)
    .collect_text().await?;

// ... later, in a new session:

// Maintainer: resumes from named context
let state = Context::lookup(&model, "project-state")
    .expect("Project state should exist");

state.user("Add authentication middleware to the API.");
state.cue();
let update = state.generate(sampler)
    .with_max_tokens(512)
    .collect_text().await?;
```

:::tip[Why Pie]
`Context::lookup()` retrieves a named context with its full KV cache intact. The Maintainer resumes with complete memory of the initialization — no re-prompting or state serialization needed.
:::

---

## Multi-Model Orchestration

Pipeline multiple models: a retrieval model gathers context, a generation model produces output, and an application model finalizes.

*[Reference →](https://agentic-patterns.com/patterns/multi-model-orchestration-for-complex-edits/)*

**When to use:**
- Complex operations requiring different model strengths
- Need to combine specialized models (small + large)
- Tasks with distinct retrieval, generation, and application phases

```
 Task ──▶ Small Model ──▶ Context ──▶ Large Model ──▶ Solution
          (retrieval)                  (generation)
```

```rust
// Stage 1: Retrieval model gathers relevant context
let retrieval_model = Model::load_by_name("small-model")?;
let retriever = Context::create(&retrieval_model, "retrieval", None)?;
retriever.system("Extract the most relevant code snippets for this task.");
retriever.user(&task);
retriever.cue();
let context = retriever.generate(sampler_fast.clone())
    .with_max_tokens(256)
    .collect_text().await?;

// Stage 2: Large model generates solution using retrieved context
let gen_model = Model::load_by_name("large-model")?;
let generator = Context::create(&gen_model, "generation", None)?;
generator.system("You are an expert programmer.");
generator.user(&format!("Context:\n{context}\n\nTask: {task}"));
generator.cue();
let solution = generator.generate(sampler_strong)
    .with_max_tokens(1024)
    .collect_text().await?;
```

---

## Discrete Phase Separation

Break a workflow into isolated phases (Research → Plan → Execute), each with a fresh context. Pass only distilled conclusions between phases, not full history.

*[Reference →](https://agentic-patterns.com/patterns/discrete-phase-separation/)*

**When to use:**
- Complex features needing background research
- Mixing research and implementation hurts quality
- Want to use different prompting strategies per phase

```
 Research ctx ──▶ findings ──▶ Plan ctx ──▶ plan ──▶ Execute ctx ──▶ code
  (thorough)     (distilled)   (concise)  (distilled) (precise)
```

```rust
// Phase 1: Research (fresh context)
let research = Context::create(&model, "research", None)?;
research.system("You are a researcher. Be thorough and cite sources.");
research.user(&format!("Research how to implement: {feature}"));
research.cue();
let findings = research.generate(sampler.clone())
    .with_max_tokens(1024)
    .collect_text().await?;

// Phase 2: Plan (fresh context, distilled input)
let planning = Context::create(&model, "plan", None)?;
planning.system("You are a technical architect. Be concise and specific.");
planning.user(&format!("Based on these findings, create a plan:\n{findings}"));
planning.cue();
let plan = planning.generate(sampler.clone())
    .with_max_tokens(512)
    .collect_text().await?;

// Phase 3: Execute (fresh context, only the plan)
let execution = Context::create(&model, "execute", None)?;
execution.system("You are an expert implementer. Follow the plan exactly.");
execution.user(&format!("Implement step 1 of this plan:\n{plan}"));
execution.cue();
let code = execution.generate(sampler)
    .with_max_tokens(1024)
    .collect_text().await?;
```

:::tip[Why Pie]
Each phase gets a clean context — no context contamination from previous phases. The distilled handoff (findings → plan → step) keeps each context focused. All phases run in the same inferlet, sharing the model.
:::

---

## Three-Stage Perception

Separate the agent workflow into Perception (input normalization), Processing (reasoning), and Action (execution). Each stage is independently debuggable and swappable.

*[Reference →](https://agentic-patterns.com/patterns/three-stage-perception-architecture/)*

**When to use:**
- Complex multi-modal inputs
- Need independent component scaling
- Want clean separation of concerns

```
 Raw Input ──▶ Perceive ──▶ Structured ──▶ Process ──▶ Decision ──▶ Act
              (normalize)    (JSON)       (reason)     (JSON)    (execute)
```

```rust
// Stage 1: Perception — normalize input
let perceive = Context::create(&model, "perceive", None)?;
perceive.system(
    "Extract structured information from the input. \
     Output JSON with: intent, entities, sentiment."
);
perceive.user(&raw_input);
perceive.cue();
let perception = perceive.generate(sampler.clone())
    .with_constraint(perception_schema.clone())
    .with_max_tokens(128)
    .collect_text().await?;

// Stage 2: Processing — reason and decide
let process = Context::create(&model, "process", None)?;
process.system("You are a decision engine. Given structured input, \
    decide the best action.");
process.user(&perception);
process.cue();
let decision = process.generate(sampler.clone())
    .with_constraint(action_schema.clone())
    .with_max_tokens(64)
    .collect_text().await?;

// Stage 3: Action — execute
let action: Action = serde_json::from_str(&decision)?;
execute_action(&action).await?;
```

---

## Next Steps

- **[Context & Memory](./context-memory)** — Patterns for managing what the model sees
- **[Feedback Loops](./feedback-loops)** — Patterns for iterative refinement
- **[KV Cache Control](../writing-inferlets/kv-cache)** — Forking and context management
- **[I/O & Messaging](../writing-inferlets/io)** — Inter-context communication
